{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_TEST1_J058.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aashu1328/Deep-Learning/blob/master/DL_TEST1_J058.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opGlV4yfpuJ3",
        "colab_type": "text"
      },
      "source": [
        "RMSPROP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzTKcsbcw5We",
        "colab_type": "code",
        "outputId": "d0bc2db9-6101-4673-d91d-00c961fbee94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.2324 - acc: 0.9275 - val_loss: 0.1343 - val_acc: 0.9579\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0858 - acc: 0.9736 - val_loss: 0.0907 - val_acc: 0.9719\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0554 - acc: 0.9829 - val_loss: 0.0739 - val_acc: 0.9780\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0415 - acc: 0.9870 - val_loss: 0.1002 - val_acc: 0.9735\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0304 - acc: 0.9901 - val_loss: 0.0676 - val_acc: 0.9813\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0245 - acc: 0.9923 - val_loss: 0.0842 - val_acc: 0.9802\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0196 - acc: 0.9942 - val_loss: 0.0804 - val_acc: 0.9825\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 0.0145 - acc: 0.9955 - val_loss: 0.0843 - val_acc: 0.9814\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0122 - acc: 0.9961 - val_loss: 0.0934 - val_acc: 0.9834\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0116 - acc: 0.9963 - val_loss: 0.1252 - val_acc: 0.9789\n",
            "Test loss: 0.12516248568999414\n",
            "Test accuracy: 0.9789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmDG5W9Kqlyb",
        "colab_type": "text"
      },
      "source": [
        "SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zweqHK6txKhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "sgd=keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6nY5sTfp2S1",
        "colab_type": "code",
        "outputId": "ed4f86ab-a6b4-4990-a31e-f3af5acfe43a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0057 - acc: 0.9982 - val_loss: 0.0940 - val_acc: 0.9840\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0911 - val_acc: 0.9840\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0899 - val_acc: 0.9841\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0893 - val_acc: 0.9841\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 5s 92us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0888 - val_acc: 0.9842\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0886 - val_acc: 0.9841\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0883 - val_acc: 0.9842\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0881 - val_acc: 0.9845\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0880 - val_acc: 0.9844\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0012 - acc: 0.9999 - val_loss: 0.0879 - val_acc: 0.9844\n",
            "Test loss: 0.08791895835404025\n",
            "Test accuracy: 0.9844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ontrSl3Vq6V9",
        "colab_type": "text"
      },
      "source": [
        "ADAGRAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q6y4loEqV2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "ada=keras.optimizers.Adagrad(lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oavg57Bzq7dX",
        "colab_type": "code",
        "outputId": "d6a00f77-3f84-4311-b73b-6205a2d76625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=ada,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0419 - acc: 0.9935 - val_loss: 0.0851 - val_acc: 0.9824\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0794 - val_acc: 0.9853\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 8.7875e-04 - acc: 0.9999 - val_loss: 0.0807 - val_acc: 0.9847\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 7.1353e-04 - acc: 1.0000 - val_loss: 0.0809 - val_acc: 0.9848\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 6.7946e-04 - acc: 1.0000 - val_loss: 0.0816 - val_acc: 0.9852\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 6.6013e-04 - acc: 1.0000 - val_loss: 0.0819 - val_acc: 0.9851\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 6.4630e-04 - acc: 1.0000 - val_loss: 0.0824 - val_acc: 0.9850\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 6.3570e-04 - acc: 1.0000 - val_loss: 0.0828 - val_acc: 0.9850\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 6.2753e-04 - acc: 1.0000 - val_loss: 0.0831 - val_acc: 0.9849\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 6.2086e-04 - acc: 1.0000 - val_loss: 0.0835 - val_acc: 0.9848\n",
            "Test loss: 0.08351262387600827\n",
            "Test accuracy: 0.9848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fb7gYA0rM7o",
        "colab_type": "text"
      },
      "source": [
        "Adadelta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1JFmAC-q_42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adelta=keras.optimizers.Adadelta(lr=1.0, rho=0.95)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbCNSam9rQgO",
        "colab_type": "code",
        "outputId": "08d51333-7b41-46ba-9959-19b6611d607c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adelta,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 6.1795e-04 - acc: 1.0000 - val_loss: 0.0843 - val_acc: 0.9848\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 6.0472e-04 - acc: 1.0000 - val_loss: 0.0856 - val_acc: 0.9849\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 5.9604e-04 - acc: 1.0000 - val_loss: 0.0864 - val_acc: 0.9849\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 5.8749e-04 - acc: 1.0000 - val_loss: 0.0866 - val_acc: 0.9848\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 5.8291e-04 - acc: 1.0000 - val_loss: 0.0868 - val_acc: 0.9852\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 5.7791e-04 - acc: 1.0000 - val_loss: 0.0879 - val_acc: 0.9849\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 5.7477e-04 - acc: 1.0000 - val_loss: 0.0880 - val_acc: 0.9848\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 5.7202e-04 - acc: 1.0000 - val_loss: 0.0884 - val_acc: 0.9849\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 5.6937e-04 - acc: 1.0000 - val_loss: 0.0889 - val_acc: 0.9847\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 5.6755e-04 - acc: 1.0000 - val_loss: 0.0891 - val_acc: 0.9851\n",
            "Test loss: 0.0890998488293475\n",
            "Test accuracy: 0.9851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66CsXiPdr7I5",
        "colab_type": "text"
      },
      "source": [
        "Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBwBfbqnrSNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSd6FaeasCuR",
        "colab_type": "code",
        "outputId": "85342d23-2531-420f-9f2c-f5c08d2d0a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0200 - acc: 0.9945 - val_loss: 0.1096 - val_acc: 0.9779\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0131 - acc: 0.9960 - val_loss: 0.1185 - val_acc: 0.9753\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 0.0123 - acc: 0.9962 - val_loss: 0.1070 - val_acc: 0.9809\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0127 - acc: 0.9960 - val_loss: 0.1011 - val_acc: 0.9796\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0109 - acc: 0.9968 - val_loss: 0.0857 - val_acc: 0.9829\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0089 - acc: 0.9975 - val_loss: 0.0801 - val_acc: 0.9810\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0141 - acc: 0.9957 - val_loss: 0.0907 - val_acc: 0.9830\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0097 - acc: 0.9968 - val_loss: 0.1159 - val_acc: 0.9775\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0945 - val_acc: 0.9823\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0058 - acc: 0.9982 - val_loss: 0.0932 - val_acc: 0.9829\n",
            "Test loss: 0.09316939825770583\n",
            "Test accuracy: 0.9829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bd5mr18sHZv",
        "colab_type": "text"
      },
      "source": [
        "Adamax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBQrKUiusEUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bud2pqJlsN3z",
        "colab_type": "code",
        "outputId": "928f647d-1a47-4f69-951e-465396d63d07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0874 - val_acc: 0.9864\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 3.6652e-04 - acc: 1.0000 - val_loss: 0.0872 - val_acc: 0.9864\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 2.9477e-04 - acc: 1.0000 - val_loss: 0.0874 - val_acc: 0.9866\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 2.8595e-04 - acc: 1.0000 - val_loss: 0.0879 - val_acc: 0.9869\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 2.8081e-04 - acc: 1.0000 - val_loss: 0.0891 - val_acc: 0.9871\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 2.7722e-04 - acc: 1.0000 - val_loss: 0.0901 - val_acc: 0.9872\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 2.7461e-04 - acc: 1.0000 - val_loss: 0.0917 - val_acc: 0.9872\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 2.7255e-04 - acc: 1.0000 - val_loss: 0.0929 - val_acc: 0.9872\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 102us/step - loss: 2.7128e-04 - acc: 1.0000 - val_loss: 0.0946 - val_acc: 0.9874\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 2.7037e-04 - acc: 1.0000 - val_loss: 0.0965 - val_acc: 0.9872\n",
            "Test loss: 0.096515276717694\n",
            "Test accuracy: 0.9872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj7QipewtpFx",
        "colab_type": "text"
      },
      "source": [
        "Nadam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWfDJVmCsY2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "nadam=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_R_H6G1zyIT",
        "colab_type": "code",
        "outputId": "04217704-f783-448e-9e86-08aeb7157e25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=nadam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 125us/step - loss: 0.0339 - acc: 0.9919 - val_loss: 0.1114 - val_acc: 0.9836\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0241 - acc: 0.9938 - val_loss: 0.1242 - val_acc: 0.9783\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0179 - acc: 0.9950 - val_loss: 0.1506 - val_acc: 0.9751\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 126us/step - loss: 0.0215 - acc: 0.9935 - val_loss: 0.1186 - val_acc: 0.9788\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0165 - acc: 0.9950 - val_loss: 0.1018 - val_acc: 0.9822\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0181 - acc: 0.9949 - val_loss: 0.1329 - val_acc: 0.9773\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0200 - acc: 0.9946 - val_loss: 0.1077 - val_acc: 0.9812\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0227 - acc: 0.9936 - val_loss: 0.1248 - val_acc: 0.9792\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0165 - acc: 0.9953 - val_loss: 0.1059 - val_acc: 0.9822\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0146 - acc: 0.9961 - val_loss: 0.1198 - val_acc: 0.9793\n",
            "Test loss: 0.11980128945739393\n",
            "Test accuracy: 0.9793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xok-Lhkz0WQ",
        "colab_type": "code",
        "outputId": "4f6ec646-5c1e-4ebf-b994-06aa35907316",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "#Training\n",
        "history = model.fit(X_train, y_train, batch_size=128, nb_epoch=10, verbose=1, validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " 1664/60000 [..............................] - ETA: 6s - loss: 0.0192 - acc: 0.9952"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0201 - acc: 0.9948 - val_loss: 0.1205 - val_acc: 0.9816\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0144 - acc: 0.9964 - val_loss: 0.1220 - val_acc: 0.9796\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0122 - acc: 0.9964 - val_loss: 0.1133 - val_acc: 0.9808\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0146 - acc: 0.9964 - val_loss: 0.1169 - val_acc: 0.9810\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0103 - acc: 0.9972 - val_loss: 0.1032 - val_acc: 0.9832\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0106 - acc: 0.9970 - val_loss: 0.1171 - val_acc: 0.9820\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0172 - acc: 0.9959 - val_loss: 0.1086 - val_acc: 0.9828\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0192 - acc: 0.9952 - val_loss: 0.1135 - val_acc: 0.9824\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0099 - acc: 0.9973 - val_loss: 0.1163 - val_acc: 0.9823\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0150 - acc: 0.9962 - val_loss: 0.1200 - val_acc: 0.9828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1IQOqBfAk5s",
        "colab_type": "code",
        "outputId": "19cc0ed3-0e76-41c8-b9a6-1239eef88f72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KW-SRCsAs0s",
        "colab_type": "code",
        "outputId": "b855d94c-4663-4c9a-cd8b-dbc9da727626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "#Model Summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbWieIfXAtjD",
        "colab_type": "code",
        "outputId": "2ee5c886-abf0-4c7d-87f5-4bb82fcad851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "# Output network visualization\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"352pt\" viewBox=\"0.00 0.00 181.00 264.00\" width=\"241pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 260)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 177,-260 177,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140708404442896 -->\n<g class=\"node\" id=\"node1\">\n<title>140708404442896</title>\n<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 173,-255.5 173,-219.5 0,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-233.8\">dense_1_input: InputLayer</text>\n</g>\n<!-- 140709939232496 -->\n<g class=\"node\" id=\"node2\">\n<title>140709939232496</title>\n<polygon fill=\"none\" points=\"33,-146.5 33,-182.5 140,-182.5 140,-146.5 33,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-160.8\">dense_1: Dense</text>\n</g>\n<!-- 140708404442896&#45;&gt;140709939232496 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140708404442896-&gt;140709939232496</title>\n<path d=\"M86.5,-219.4551C86.5,-211.3828 86.5,-201.6764 86.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-192.5903 86.5,-182.5904 83.0001,-192.5904 90.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140708404442112 -->\n<g class=\"node\" id=\"node3\">\n<title>140708404442112</title>\n<polygon fill=\"none\" points=\"33,-73.5 33,-109.5 140,-109.5 140,-73.5 33,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-87.8\">dense_2: Dense</text>\n</g>\n<!-- 140709939232496&#45;&gt;140708404442112 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140709939232496-&gt;140708404442112</title>\n<path d=\"M86.5,-146.4551C86.5,-138.3828 86.5,-128.6764 86.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-119.5903 86.5,-109.5904 83.0001,-119.5904 90.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140708391436072 -->\n<g class=\"node\" id=\"node4\">\n<title>140708391436072</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-36.5 140,-36.5 140,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-14.8\">dense_3: Dense</text>\n</g>\n<!-- 140708404442112&#45;&gt;140708391436072 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140708404442112-&gt;140708391436072</title>\n<path d=\"M86.5,-73.4551C86.5,-65.3828 86.5,-55.6764 86.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-46.5903 86.5,-36.5904 83.0001,-46.5904 90.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQa-pDJvBR4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "28"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
